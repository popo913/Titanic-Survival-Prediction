# Titanic-Survival-Prediction
It is a project aiming to create a machine learning model that is trained to accurately predict whether a passenger survived the titanic disaster.The dataset used is the <a href = "https://www.kaggle.com/datasets/brendan45774/test-file">"Titanic dataset"</a>. 
The dataset contains features like age,gender,ticket class,fare,cabin information etc. 
The model is capable of handling missing values and encode categorical variables and normalize data effectively.</br>
<h2>TASK OBJECTIVES</h2><hr>
<ol>
  <li>Develop a machine learning model to predict whether a passenger survived the Titanic disaster.</li>
  <li>Dataset includes features like age, gender, ticket class, fare, cabin information etc.</li>
  <li>Handle missing values, encode categorical variables, and normalize numerical data effectively.</li>
  <li>Evaluate model performance using accuracy, precision, etc.</li>
  <li>Expected outcome: A well-trained classification model with strong survival prediction accuracy.</li>
</ol>
<h2>STEPS TO RUN THE PROJECT</h2><hr>
<ol><li>
  <h4>Install the dependencies:</h4>Install the required libraries and extensions such as Pandas,NumPy etc.</li>
<li><h4>Load the dataset:</h4>Prepare the dataset i.e titanic dataset , find the path and documentation of the dataset. We then determine features of the dataset. I used Google Colab for making the project so i uploaded the downloaded dataset "tested.csv" onto Google Colab.</li>
<li><h4>Train the model:</h4>Code the needed program to train the model and then run the script.</li>
<li><h4>Expected Output:</h4>If the code is correct ,data is properly loaded then we expect the following:</li>
<ol>
  <li>Preprocessing of data</li>
  <li>Training the random model on the dataset</li>
  <li>Display perfomance metrics like accuracy,F1 score etc</li>
  <li>Save the trained model.</li>
</ol>
</ol>
<h2>INNOVATION AND CREATIVITY</h2>
<ol>
  <li>Implemented automated data preprocessing, handling missing values and encoding categorical data efficiently.</li>
  <li>Used feature engineering (one-hot encoding for Embarked, label encoding for Sex, and scaling for Age & Fare) to improve model performance.</li>
  <li>Ensured a modular code structure, making it reusable and easy to extend with other models like Logistic Regression or XGBoost.
</li>
  <li>Saved the trained model & scaler for future predictions, enabling real-world deployment.</li>
  <li>Evaluated the model using multiple metrics (accuracy, precision, recall, F1-score) for a balanced assessment instead of relying only on accuracy.</li>
</ol>
<h2>DOCUMENTATION</h2>
<ol>
  <li>Code is structured into functions for loading data, preprocessing, training, and saving the model, making it easy to understand.</li>
  <li>Added error handling to avoid crashes due to missing files or incorrect data.
</li>
  <li>Explained all key steps (preprocessing, training, evaluation) in the code with comments.</li>
  <li>Outputs clear logs for accuracy and model performance, helping with debugging and improvements.</li>
</ol>


